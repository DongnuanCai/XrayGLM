{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo8wVmRKkgBj",
        "outputId": "7ce66ffc-db70-4d5e-cf3a-0bf1ae53edf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 20 07:15:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNfV5F3zknhi",
        "outputId": "724535e8-a8cf-43a6-f92b-6a0d6d67e556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XrayGLM'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 377 (delta 100), reused 58 (delta 49), pack-reused 246\u001b[K\n",
            "Receiving objects: 100% (377/377), 9.21 MiB | 26.06 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DongnuanCai/XrayGLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN88j0lqf6bx",
        "outputId": "60da4a22-58a2-457a-eb1d-5b455c02e455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/XrayGLM\n"
          ]
        }
      ],
      "source": [
        "%cd XrayGLM/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-G7I4DOf9vI",
        "outputId": "75f6b886-e655-49db-ddad-a05357b39800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SwissArmyTransformer>=0.3.6 (from -r requirements.txt (line 1))\n",
            "  Downloading SwissArmyTransformer-0.4.11-py3-none-any.whl (2.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>1.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.17.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.27.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.38.2)\n",
            "Collecting mdtex2html (from -r requirements.txt (line 5))\n",
            "  Downloading mdtex2html-1.3.0-py3-none-any.whl (13 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 6))\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.39.0 (from -r requirements.txt (line 7))\n",
            "  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (0.1.99)\n",
            "Collecting tensorboardX (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cpm-kernels (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading boto3-1.34.66-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset (from SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading webdataset-0.2.86-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->-r requirements.txt (line 2)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>1.10.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.1->-r requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mdtex2html->-r requirements.txt (line 5)) (3.6)\n",
            "Collecting latex2mathml (from mdtex2html->-r requirements.txt (line 5))\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (6.3.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (2.6.4)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading ruff-0.3.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 6)) (0.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 6))\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio->-r requirements.txt (line 6))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 6)) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 6)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 6)) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6)) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6)) (13.7.1)\n",
            "Collecting botocore<1.35.0,>=1.34.66 (from boto3->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading botocore-1.34.66-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.27.1->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.27.1->-r requirements.txt (line 4)) (2.0.7)\n",
            "Collecting hjson (from deepspeed->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (9.0.0)\n",
            "Collecting pynvml (from deepspeed->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio->-r requirements.txt (line 6))\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>1.10.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (3.20.3)\n",
            "Collecting braceexpand (from webdataset->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1))\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.3.6->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 6)) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 6)) (0.1.2)\n",
            "Building wheels for collected packages: deepspeed, ffmpy\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400405 sha256=2356f98d28002342db7889ed4ffcb96450b0dbb213d79f6d2de1ca150d5561b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=70b4a42f78e83a8fe0564bebd9348ea91587f6021d1ea48884cba3ea8629ab2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built deepspeed ffmpy\n",
            "Installing collected packages: pydub, ninja, hjson, ffmpy, cpm-kernels, braceexpand, bitsandbytes, xxhash, websockets, webdataset, tomlkit, tensorboardX, shellingham, semantic-version, ruff, python-multipart, pynvml, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, latex2mathml, jmespath, h11, einops, dill, colorama, aiofiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, mdtex2html, httpcore, botocore, s3transfer, nvidia-cusolver-cu12, httpx, fastapi, gradio-client, datasets, boto3, gradio, deepspeed, SwissArmyTransformer\n",
            "Successfully installed SwissArmyTransformer-0.4.11 aiofiles-23.2.1 bitsandbytes-0.39.0 boto3-1.34.66 botocore-1.34.66 braceexpand-0.1.7 colorama-0.4.6 cpm-kernels-1.0.11 datasets-2.18.0 deepspeed-0.14.0 dill-0.3.8 einops-0.7.0 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 h11-0.14.0 hjson-3.1.0 httpcore-1.0.4 httpx-0.27.0 jmespath-1.0.1 latex2mathml-3.77.0 mdtex2html-1.3.0 multiprocess-0.70.16 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 orjson-3.9.15 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.9 ruff-0.3.3 s3transfer-0.10.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tensorboardX-2.6.2.2 tomlkit-0.12.0 uvicorn-0.29.0 webdataset-0.2.86 websockets-11.0.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmcU1hIgf-wh"
      },
      "outputs": [],
      "source": [
        "\n",
        "%cd checkpoints/\n",
        "!wget https://huggingface.co/wangrongsheng/XrayGLM-3000/resolve/main/latest\n",
        "!wget https://huggingface.co/wangrongsheng/XrayGLM-3000/resolve/main/model_config.json\n",
        "\n",
        "!mkdir 3000\n",
        "%cd 3000/\n",
        "!wget https://huggingface.co/wangrongsheng/XrayGLM-3000/resolve/main/3000/mp_rank_00_model_states.pt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gHGSonXgBb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce726a59-ee93-4c5d-f498-e35f16848a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m3000\u001b[0m/  latest  model_config.json  README.md\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll-5UHPGgDKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516477fb-a700-4dce-cb3f-2d9ded2e647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/XrayGLM\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67h5pZ_ogFka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db3ff47-69f1-4b95-fe1a-8f39b121b51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-17 08:22:10--  https://github.com/WangRongsheng/XrayGLM/blob/main/data/Xray/2577_1.png\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5737 (5.6K) [text/plain]\n",
            "Saving to: ‘2577_1.png’\n",
            "\n",
            "2577_1.png          100%[===================>]   5.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-17 08:22:10 (85.0 MB/s) - ‘2577_1.png’ saved [5737/5737]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/WangRongsheng/XrayGLM/blob/main/data/Xray/2577_1.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-100oZtKgJa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3423328d-fe81-4852-84e8-12d176d00111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/XrayGLM\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['SAT_HOME'] = '/content/XrayGLM'\n",
        "!echo $SAT_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ImCjC2gJd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475b9a7a-ee60-447a-8e6a-adfb047be789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKSYfcFzgJgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea9b6dc-8947-4944-9bf6-296ed581929f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.66)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.66 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.66)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.66->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.66->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.66->boto3) (1.16.0)\n",
            "Collecting SwissArmyTransformer==0.4.4\n",
            "  Downloading SwissArmyTransformer-0.4.4-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (2.2.1+cu121)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (0.14.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (0.1.99)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (2.6.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (2.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (4.38.2)\n",
            "Requirement already satisfied: cpm-kernels in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (1.0.11)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (0.7.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer==0.4.4) (1.34.66)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.66 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer==0.4.4) (1.34.66)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer==0.4.4) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer==0.4.4) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer==0.4.4) (6.0.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (2.6.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer==0.4.4) (11.5.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->SwissArmyTransformer==0.4.4) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->SwissArmyTransformer==0.4.4) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->SwissArmyTransformer==0.4.4) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->SwissArmyTransformer==0.4.4) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->SwissArmyTransformer==0.4.4) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->SwissArmyTransformer==0.4.4) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.66->boto3->SwissArmyTransformer==0.4.4) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.66->boto3->SwissArmyTransformer==0.4.4) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer==0.4.4) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->SwissArmyTransformer==0.4.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->SwissArmyTransformer==0.4.4) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->SwissArmyTransformer==0.4.4) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->SwissArmyTransformer==0.4.4) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->SwissArmyTransformer==0.4.4) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed->SwissArmyTransformer==0.4.4) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed->SwissArmyTransformer==0.4.4) (2.16.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->SwissArmyTransformer==0.4.4) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.66->boto3->SwissArmyTransformer==0.4.4) (1.16.0)\n",
            "Installing collected packages: SwissArmyTransformer\n",
            "  Attempting uninstall: SwissArmyTransformer\n",
            "    Found existing installation: SwissArmyTransformer 0.4.11\n",
            "    Uninstalling SwissArmyTransformer-0.4.11:\n",
            "      Successfully uninstalled SwissArmyTransformer-0.4.11\n",
            "Successfully installed SwissArmyTransformer-0.4.4\n",
            "Requirement already satisfied: bitsandbytes==0.39.0 in /usr/local/lib/python3.10/dist-packages (0.39.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3 --upgrade\n",
        "!pip install SwissArmyTransformer==0.4.4\n",
        "!pip install bitsandbytes==0.39.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG3wJ43SgO0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268f2ffa-fff2-415b-abc5-f4aa79dd57bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: bitsandbytes 0.39.0\n",
            "Uninstalling bitsandbytes-0.39.0:\n",
            "  Successfully uninstalled bitsandbytes-0.39.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall bitsandbytes -y\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REIj1U4bgRfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6eab3a-9c57-4b45-ff94-7a05929ed369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.33.2\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.33.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0_QoSPHgTA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46900fe1-a6ba-46fc-d4fb-1ab7b6379ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==3.50.2\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.3.2)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (3.9.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (2.6.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (4.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (0.29.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2) (11.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50.2) (2024.2.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.50.2) (0.36.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2) (1.0.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.50.2) (1.2.0)\n",
            "Installing collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 0.13.0\n",
            "    Uninstalling gradio_client-0.13.0:\n",
            "      Successfully uninstalled gradio_client-0.13.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 4.22.0\n",
            "    Uninstalling gradio-4.22.0:\n",
            "      Successfully uninstalled gradio-4.22.0\n",
            "Successfully installed gradio-3.50.2 gradio-client-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio==3.50.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwg7ev9dgUxu",
        "outputId": "cb76c0e3-fa36-48e8-cdb7-f0e6d2c3d06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-03-20 07:17:34,635] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-03-20 07:17:36.616285: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 07:17:36.616324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 07:17:36.617622: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 07:17:37.716649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "[2024-03-20 07:17:40,218] [INFO] building FineTuneVisualGLMModel model ...\n",
            "[2024-03-20 07:17:40,221] [INFO] [RANK 0] > initializing model parallel with size 1\n",
            "[2024-03-20 07:17:40,222] [INFO] [RANK 0] You are using model-only mode.\n",
            "For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "replacing layer 0 attention with lora\n",
            "replacing layer 14 attention with lora\n",
            "[2024-03-20 07:17:55,225] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 7802848768\n",
            "[2024-03-20 07:17:57,713] [INFO] [RANK 0] global rank 0 is loading checkpoint /content/drive/MyDrive/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt\n",
            "[2024-03-20 07:22:54,877] [INFO] [RANK 0] > successfully loaded /content/drive/MyDrive/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt\n",
            "tokenizer_config.json: 100% 441/441 [00:00<00:00, 1.59MB/s]\n",
            "tokenization_chatglm.py: 100% 17.0k/17.0k [00:00<00:00, 57.6MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n",
            "- tokenization_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "ice_text.model: 100% 2.71M/2.71M [00:00<00:00, 47.3MB/s]\n",
            "/content/XrayGLM/web_demo.py:113: GradioDeprecationWarning: 'scale' value should be an integer. Using 4.5 will cause issues.\n",
            "  with gr.Column(scale=4.5):\n",
            "/content/XrayGLM/web_demo.py:127: GradioDeprecationWarning: 'scale' value should be an integer. Using 5.5 will cause issues.\n",
            "  with gr.Column(scale=5.5):\n",
            "/content/XrayGLM/web_demo.py:128: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  result_text = gr.components.Chatbot(label='Multi-round conversation History', value=[(\"\", \"Hi, What do you want to know about this image?\")]).style(height=550)\n",
            "3.50.2\n",
            "3.50.2\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://f47b05c28a6cd1c75f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "history []\n",
            "[('详细说明病情', '心脏结构正常，肺部未见明显异常。')]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2361, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/XrayGLM/web_demo.py\", line 154, in <module>\n",
            "    main(args)\n",
            "  File \"/content/XrayGLM/web_demo.py\", line 144, in main\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2266, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2365, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 70, in close\n",
            "    def close(self):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f47b05c28a6cd1c75f.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python web_demo.py --from_pretrained /content/drive/MyDrive/finetune-XrayGLM-03-20-03-04"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "def unzip_and_replace(zip_file_path, extract_folder):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "\n",
        "    for root, _, files in os.walk(extract_folder):\n",
        "        for file in files:\n",
        "            original_file_path = os.path.join(root, file)\n",
        "            replacement_file_path = os.path.join(os.path.dirname(zip_file_path), \"Xray\", file)\n",
        "            if os.path.exists(replacement_file_path):\n",
        "                os.remove(original_file_path)\n",
        "                shutil.move(replacement_file_path, os.path.dirname(original_file_path))\n",
        "\n",
        "zip_file_path = r'/content/drive/MyDrive/images2.zip'\n",
        "extract_folder = r'/content/XrayGLM/data/Xray'\n",
        "\n",
        "unzip_and_replace(zip_file_path, extract_folder)"
      ],
      "metadata": {
        "id": "Eo1jZvg6fepy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0"
      ],
      "metadata": {
        "id": "mQenW_76iuHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQClAz_yESve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09735028-8905-406e-a9b4-8535e1abc6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port 16666 --hostfile hostfile_single finetune_XrayGLM.py --experiment-name finetune-XrayGLM --model-parallel-size 1 --mode finetune --train-iters 500 --resume-dataloader --max_source_length 64 --max_target_length 256 --lora_rank 10 --pre_seq_len 4 --train-data ./data/Xray/openi-zh.json --valid-data ./data/Xray/openi-zh.json --distributed-backend nccl --lr-decay-style cosine --warmup .02 --checkpoint-activations --save-interval 500 --eval-interval 10000 --save ./checkpoints --split 1 --eval-iters 10 --eval-batch-size 8 --zero-stage 1 --lr 0.0001 --batch-size 8 --skip-init --fp16 --use_lora\n",
            "[2024-03-20 03:00:37,153] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-03-20 03:00:39.421337: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 03:00:39.421444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 03:00:39.423398: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 03:00:40.654420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "[2024-03-20 03:00:41,487] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-03-20 03:00:41,488] [INFO] [runner.py:568:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=16666 --enable_each_rank_log=None finetune_XrayGLM.py --experiment-name finetune-XrayGLM --model-parallel-size 1 --mode finetune --train-iters 500 --resume-dataloader --max_source_length 64 --max_target_length 256 --lora_rank 10 --pre_seq_len 4 --train-data ./data/Xray/openi-zh.json --valid-data ./data/Xray/openi-zh.json --distributed-backend nccl --lr-decay-style cosine --warmup .02 --checkpoint-activations --save-interval 500 --eval-interval 10000 --save ./checkpoints --split 1 --eval-iters 10 --eval-batch-size 8 --zero-stage 1 --lr 0.0001 --batch-size 8 --skip-init --fp16 --use_lora\n",
            "[2024-03-20 03:00:44,482] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-03-20 03:00:45.957959: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 03:00:45.958010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 03:00:45.959181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 03:00:47.164391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "[2024-03-20 03:00:47,982] [INFO] [launch.py:138:main] 0 NCCL_IB_DISABLE=0\n",
            "[2024-03-20 03:00:47,982] [INFO] [launch.py:138:main] 0 NCCL_DEBUG=info\n",
            "[2024-03-20 03:00:47,982] [INFO] [launch.py:138:main] 0 NCCL_NET_GDR_LEVEL=2\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-03-20 03:00:47,983] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-03-20 03:00:47,984] [INFO] [launch.py:253:main] process 4007 spawned with command: ['/usr/bin/python3', '-u', 'finetune_XrayGLM.py', '--local_rank=0', '--experiment-name', 'finetune-XrayGLM', '--model-parallel-size', '1', '--mode', 'finetune', '--train-iters', '500', '--resume-dataloader', '--max_source_length', '64', '--max_target_length', '256', '--lora_rank', '10', '--pre_seq_len', '4', '--train-data', './data/Xray/openi-zh.json', '--valid-data', './data/Xray/openi-zh.json', '--distributed-backend', 'nccl', '--lr-decay-style', 'cosine', '--warmup', '.02', '--checkpoint-activations', '--save-interval', '500', '--eval-interval', '10000', '--save', './checkpoints', '--split', '1', '--eval-iters', '10', '--eval-batch-size', '8', '--zero-stage', '1', '--lr', '0.0001', '--batch-size', '8', '--skip-init', '--fp16', '--use_lora']\n",
            "[2024-03-20 03:00:50,895] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-03-20 03:00:52.364662: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 03:00:52.364725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 03:00:52.366522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 03:00:53.556823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "[2024-03-20 03:00:55,604] [INFO] using world size: 1 and model-parallel size: 1 \n",
            "[2024-03-20 03:00:55,604] [INFO] > padded vocab (size: 100) with 28 dummy tokens (new size: 128)\n",
            "[2024-03-20 03:00:55,607] [INFO] [RANK 0] > initializing model parallel with size 1\n",
            "[2024-03-20 03:00:55,607] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-03-20 03:00:55,608] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "[2024-03-20 03:00:55,608] [INFO] [checkpointing.py:1045:_configure_using_config_file] {'partition_activations': False, 'contiguous_memory_optimization': False, 'cpu_checkpointing': False, 'number_checkpoints': None, 'synchronize_checkpoint_boundary': False, 'profile': False}\n",
            "[2024-03-20 03:00:55,609] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "Downloading models r2://visualglm-6b.zip into /content/XrayGLM ...\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++100.0% 14.4 GB / 14.4 GB     \n",
            "Unzipping /content/XrayGLM/visualglm-6b.zip...\n",
            "[2024-03-20 03:03:32,684] [INFO] [RANK 0] building FineTuneVisualGLMModel model ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "replacing layer 0 attention with lora\n",
            "replacing layer 14 attention with lora\n",
            "[2024-03-20 03:03:48,871] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 7802848768\n",
            "[2024-03-20 03:03:49,988] [INFO] [RANK 0] global rank 0 is loading checkpoint /content/XrayGLM/visualglm-6b/1/mp_rank_00_model_states.pt\n",
            "[2024-03-20 03:04:04,882] [INFO] [RANK 0] Will continue but found unexpected_keys! Check whether you are loading correct checkpoints: ['transformer.position_embeddings.weight'].\n",
            "[2024-03-20 03:04:04,882] [INFO] [RANK 0] > successfully loaded /content/XrayGLM/visualglm-6b/1/mp_rank_00_model_states.pt\n",
            "[2024-03-20 03:04:10,277] [INFO] [RANK 0] Try to load tokenizer from Huggingface transformers...\n",
            "tokenizer_config.json: 100% 441/441 [00:00<00:00, 1.96MB/s]\n",
            "tokenization_chatglm.py: 100% 17.0k/17.0k [00:00<00:00, 61.0MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n",
            "- tokenization_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "ice_text.model: 100% 2.71M/2.71M [00:00<00:00, 90.5MB/s]\n",
            "[2024-03-20 03:04:12,632] [INFO] [RANK 0] > Set tokenizer as a THUDM/chatglm-6b tokenizer! Now you can get_tokenizer() everywhere.\n",
            "0164b61283f5:4007:4007 [0] NCCL INFO Bootstrap : Using eth0:172.28.0.12<0>\n",
            "0164b61283f5:4007:4007 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation\n",
            "0164b61283f5:4007:4007 [0] NCCL INFO cudaDriverVersion 12020\n",
            "NCCL version 2.19.3+cuda12.3\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO NET/IB : No device found.\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO NET/Socket : Using [0]eth0:172.28.0.12<0>\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Using non-device net plugin version 0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Using network Socket\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO comm 0x59e16d5ef1f0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0x73d408866103288f - Init START\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Setting affinity for GPU 0 to 0fff\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 00/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 01/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 02/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 03/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 04/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 05/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 06/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 07/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 08/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 09/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 10/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 11/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 12/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 13/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 14/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 15/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 16/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 17/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 18/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 19/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 20/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 21/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 22/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 23/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 24/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 25/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 26/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 27/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 28/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 29/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 30/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Channel 31/32 :    0\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO P2P Chunksize set to 131072\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Connected all rings\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO Connected all trees\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
            "0164b61283f5:4007:5532 [0] NCCL INFO comm 0x59e16d5ef1f0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0x73d408866103288f - Init COMPLETE\n",
            "transformer.layers.0.attention.query_key_value.matrix_A.0\n",
            "transformer.layers.0.attention.query_key_value.matrix_A.1\n",
            "transformer.layers.0.attention.query_key_value.matrix_A.2\n",
            "transformer.layers.0.attention.query_key_value.matrix_B.0\n",
            "transformer.layers.0.attention.query_key_value.matrix_B.1\n",
            "transformer.layers.0.attention.query_key_value.matrix_B.2\n",
            "transformer.layers.0.attention.dense.matrix_A.0\n",
            "transformer.layers.0.attention.dense.matrix_B.0\n",
            "transformer.layers.14.attention.query_key_value.matrix_A.0\n",
            "transformer.layers.14.attention.query_key_value.matrix_A.1\n",
            "transformer.layers.14.attention.query_key_value.matrix_A.2\n",
            "transformer.layers.14.attention.query_key_value.matrix_B.0\n",
            "transformer.layers.14.attention.query_key_value.matrix_B.1\n",
            "transformer.layers.14.attention.query_key_value.matrix_B.2\n",
            "transformer.layers.14.attention.dense.matrix_A.0\n",
            "transformer.layers.14.attention.dense.matrix_B.0\n",
            "[2024-03-20 03:06:21,378] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-03-20 03:06:21,378] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Using non-device net plugin version 0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Using network Socket\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO bootstrapSplit: rank 0 nranks 1 color -1091263299 key 0 prev 0 next 0 - DONE\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO comm 0x59df12213280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0xfcca7c94a1fcb775 - Init START\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Setting affinity for GPU 0 to 0fff\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 00/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 01/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 02/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 03/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 04/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 05/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 06/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 07/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 08/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 09/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 10/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 11/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 12/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 13/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 14/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 15/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 16/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 17/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 18/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 19/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 20/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 21/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 22/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 23/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 24/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 25/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 26/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 27/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 28/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 29/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 30/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Channel 31/32 :    0\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO P2P Chunksize set to 131072\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Connected all rings\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO Connected all trees\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
            "0164b61283f5:4007:5536 [0] NCCL INFO comm 0x59df12213280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0xfcca7c94a1fcb775 - Init COMPLETE\n",
            "[2024-03-20 03:06:21,530] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/fused_adam...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -std=c++17 -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
            "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
            "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 33.1842577457428 seconds\n",
            "[2024-03-20 03:06:55,014] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2024-03-20 03:06:55,014] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-03-20 03:06:55,020] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-03-20 03:06:55,021] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-03-20 03:06:55,021] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-03-20 03:06:55,021] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 40000000\n",
            "[2024-03-20 03:06:55,021] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 100000000\n",
            "[2024-03-20 03:06:55,021] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-03-20 03:06:55,021] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-03-20 03:06:55,414] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
            "[2024-03-20 03:06:55,415] [INFO] [utils.py:801:see_memory_usage] MA 14.56 GB         Max_MA 14.56 GB         CA 14.68 GB         Max_CA 15 GB \n",
            "[2024-03-20 03:06:55,415] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 18.67 GB, percent = 22.4%\n",
            "[2024-03-20 03:06:55,755] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
            "[2024-03-20 03:06:55,756] [INFO] [utils.py:801:see_memory_usage] MA 14.56 GB         Max_MA 14.56 GB         CA 14.68 GB         Max_CA 15 GB \n",
            "[2024-03-20 03:06:55,757] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 18.67 GB, percent = 22.4%\n",
            "[2024-03-20 03:06:55,757] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
            "[2024-03-20 03:06:56,085] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-03-20 03:06:56,086] [INFO] [utils.py:801:see_memory_usage] MA 14.56 GB         Max_MA 14.56 GB         CA 14.68 GB         Max_CA 15 GB \n",
            "[2024-03-20 03:06:56,086] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 18.67 GB, percent = 22.4%\n",
            "[2024-03-20 03:06:56,087] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2024-03-20 03:06:56,087] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-03-20 03:06:56,087] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2024-03-20 03:06:56,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:06:56,089] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
            "[2024-03-20 03:06:56,090] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-03-20 03:06:56,090] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-03-20 03:06:56,090] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
            "[2024-03-20 03:06:56,090] [INFO] [config.py:1000:print]   amp_params ................... False\n",
            "[2024-03-20 03:06:56,090] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   bfloat16_enabled ............. False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7c77d412d780>\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   dump_state ................... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 400, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-03-20 03:06:56,091] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   fp16_auto_cast ............... False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   fp16_enabled ................. True\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.1\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 65536\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   loss_scale ................... 0\n",
            "[2024-03-20 03:06:56,092] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   optimizer_name ............... adam\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.01}\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   pld_params ................... False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   steps_per_print .............. 10\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   train_batch_size ............. 8\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  8\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
            "[2024-03-20 03:06:56,093] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   world_size ................... 1\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   zero_config .................. stage=1 contiguous_gradients=False reduce_scatter=True reduce_bucket_size=40000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=100000000 overlap_comm=True load_from_fp32_weights=False elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 1\n",
            "[2024-03-20 03:06:56,094] [INFO] [config.py:986:print_user_config]   json = {\n",
            "    \"train_micro_batch_size_per_gpu\": 8, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"gradient_clipping\": 0.1, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"cpu_offload\": false, \n",
            "        \"contiguous_gradients\": false, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 4.000000e+07, \n",
            "        \"allgather_bucket_size\": 1.000000e+08, \n",
            "        \"load_from_fp32_weights\": false\n",
            "    }, \n",
            "    \"zero_allow_untested_optimizer\": true, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 400, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"bf16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.0001, \n",
            "            \"betas\": [0.9, 0.95], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"activation_checkpointing\": {\n",
            "        \"partition_activations\": false, \n",
            "        \"contiguous_memory_optimization\": false\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": false\n",
            "}\n",
            "[2024-03-20 03:06:56,094] [INFO] [RANK 0] learning rate decaying style cosine, ratio 10.0\n",
            "[2024-03-20 03:06:56,094] [INFO] [RANK 0] Finetuning Model...\n",
            "[2024-03-20 03:06:56,094] [INFO] [RANK 0] arguments:\n",
            "[2024-03-20 03:06:56,094] [INFO] [RANK 0]   model_class .................. VisualGLMModel\n",
            "[2024-03-20 03:06:56,094] [INFO] [RANK 0]   tokenizer_type ............... THUDM/chatglm-6b\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   num_layers ................... 28\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   hidden_size .................. 4096\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   num_attention_heads .......... 32\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   vocab_size ................... 130528\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   layernorm_order .............. post\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   model_parallel_size .......... 1\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   max_sequence_length .......... 2048\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   image_length ................. 32\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   eva_args ..................... {'num_layers': 39, 'hidden_size': 1408, 'num_attention_heads': 16, 'vocab_size': 1, 'layernorm_order': 'pre', 'model_parallel_size': 1, 'max_sequence_length': 257, 'inner_hidden_size': 6144, 'use_final_layernorm': False, 'layernorm_epsilon': 1e-06, 'image_size': [224, 224], 'pre_len': 1, 'post_len': 0, 'in_channels': 3, 'num_classes': 0, 'patch_size': 14}\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   qformer_args ................. {'num_layers': 12, 'hidden_size': 768, 'num_attention_heads': 12, 'vocab_size': 32, 'layernorm_order': 'post', 'model_parallel_size': 1, 'max_sequence_length': 0, 'is_decoder': [True, False, True, False, True, False, True, False, True, False, True, False], 'cross_attn_hidden_size': 1408, 'layernorm_epsilon': 1e-12}\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   bos_token_id ................. 130004\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   mask_token_id ................ 130000\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   gmask_token_id ............... 130001\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   pad_token_id ................. 3\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   image_size ................... [224, 224]\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   pre_len ...................... 1\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   post_len ..................... 0\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   in_channels .................. 3\n",
            "[2024-03-20 03:06:56,095] [INFO] [RANK 0]   patch_size ................... 14\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   inner_hidden_size ............ None\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   hidden_size_per_attention_head  None\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   skip_init .................... True\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   use_gpu_initialization ....... False\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   num_multi_query_heads ........ 0\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   layernorm_epsilon ............ 1e-05\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   hidden_dropout ............... 0.1\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   attention_dropout ............ 0.1\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   make_vocab_size_divisible_by . 128\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   experiment_name .............. finetune-XrayGLM-03-20-03-04\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   train_iters .................. 500\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   batch_size ................... 8\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   lr ........................... 0.0001\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   mode ......................... finetune\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   seed ......................... 1234\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   zero_stage ................... 1\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   checkpoint_activations ....... True\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   checkpoint_num_layers ........ 1\n",
            "[2024-03-20 03:06:56,096] [INFO] [RANK 0]   fp16 ......................... True\n",
            "[2024-03-20 03:06:56,097] [INFO] [RANK 0]   bf16 ......................... False\n",
            "[2024-03-20 03:06:56,097] [INFO] [RANK 0]   gradient_accumulation_steps .. 1\n",
            "[2024-03-20 03:06:56,097] [INFO] [RANK 0]   epochs ....................... None\n",
            "[2024-03-20 03:06:56,097] [INFO] [RANK 0]   log_interval ................. 50\n",
            "[2024-03-20 03:06:56,097] [INFO] [RANK 0]   summary_dir .................. \n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   save_args .................... False\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   lr_decay_iters ............... None\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   lr_decay_style ............... cosine\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   lr_decay_ratio ............... 0.1\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   warmup ....................... 0.02\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   weight_decay ................. 0.01\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   save ......................... ./checkpoints/finetune-XrayGLM-03-20-03-04\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   load ......................... None\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   save_interval ................ 500\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   no_save_rng .................. False\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   no_load_rng .................. False\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   resume_dataloader ............ True\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   distributed_backend .......... nccl\n",
            "[2024-03-20 03:06:56,154] [INFO] [RANK 0]   local_rank ................... 0\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   exit_interval ................ None\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   eval_batch_size .............. 8\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   eval_iters ................... 10\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   eval_interval ................ 10000\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   strict_eval .................. False\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   train_data ................... ['./data/Xray/openi-zh.json']\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   train_data_weights ........... None\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   iterable_dataset ............. False\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   valid_data ................... ['./data/Xray/openi-zh.json']\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   test_data .................... None\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   split ........................ 1\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   num_workers .................. 1\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   block_size ................... 10000\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   prefetch_factor .............. 4\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   temperature .................. 1.0\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   top_p ........................ 0.0\n",
            "[2024-03-20 03:06:56,155] [INFO] [RANK 0]   top_k ........................ 0\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   num_beams .................... 1\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   length_penalty ............... 0.0\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   no_repeat_ngram_size ......... 0\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   min_tgt_length ............... 0\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   out_seq_length ............... 256\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   input_source ................. interactive\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   output_path .................. ./samples\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   with_id ...................... False\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   max_inference_batch_size ..... 12\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   device ....................... cpu\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   deepspeed .................... True\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   deepspeed_config ............. {'train_micro_batch_size_per_gpu': 8, 'gradient_accumulation_steps': 1, 'gradient_clipping': 0.1, 'zero_optimization': {'stage': 1, 'cpu_offload': False, 'contiguous_gradients': False, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 40000000.0, 'allgather_bucket_size': 100000000.0, 'load_from_fp32_weights': False}, 'zero_allow_untested_optimizer': True, 'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 400, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': False}, 'optimizer': {'type': 'Adam', 'params': {'lr': 0.0001, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.01}}, 'activation_checkpointing': {'partition_activations': False, 'contiguous_memory_optimization': False}, 'wall_clock_breakdown': False}\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   deepscale .................... False\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   deepscale_config ............. None\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   cuda ......................... True\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   rank ......................... 0\n",
            "[2024-03-20 03:06:56,156] [INFO] [RANK 0]   world_size ................... 1\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   deepspeed_activation_checkpointing  True\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   master_ip .................... 127.0.0.1\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   master_port .................. 16666\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   max_source_length ............ 64\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   max_target_length ............ 256\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   ignore_pad_token_for_loss .... True\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   source_prefix ................ \n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   pre_seq_len .................. 4\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   lora_rank .................... 10\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   use_ptuning .................. False\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   use_lora ..................... True\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   use_qlora .................... False\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   do_train ..................... True\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   val_last_shape ............... []\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   val_drop_number .............. 0\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   do_valid ..................... True\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   do_test ...................... False\n",
            "[2024-03-20 03:06:56,157] [INFO] [RANK 0]   iteration .................... 0\n",
            "/usr/local/lib/python3.10/dist-packages/sat/mpu/data.py:49: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  sizes_cuda = torch.cuda.LongTensor(sizes)\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Using non-device net plugin version 0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Using network Socket\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO bootstrapSplit: rank 0 nranks 1 color -1091263299 key 0 prev 0 next 0 - DONE\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO comm 0x59e13906b7c0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0xfcca7c94a1fcb775 - Init START\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Setting affinity for GPU 0 to 0fff\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 00/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 01/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 02/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 03/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 04/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 05/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 06/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 07/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 08/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 09/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 10/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 11/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 12/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 13/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 14/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 15/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 16/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 17/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 18/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 19/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 20/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 21/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 22/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 23/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 24/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 25/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 26/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 27/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 28/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 29/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 30/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Channel 31/32 :    0\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO P2P Chunksize set to 131072\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Connected all rings\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO Connected all trees\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
            "0164b61283f5:4007:5758 [0] NCCL INFO comm 0x59e13906b7c0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 40 commId 0xfcca7c94a1fcb775 - Init COMPLETE\n",
            "[2024-03-20 03:06:58,566] [INFO] [checkpointing.py:539:forward] Activation Checkpointing Information\n",
            "[2024-03-20 03:06:58,567] [INFO] [checkpointing.py:540:forward] ----Partition Activations False, CPU CHECKPOINTING False\n",
            "[2024-03-20 03:06:58,567] [INFO] [checkpointing.py:541:forward] ----contiguous Memory Checkpointing False with 6 total layers\n",
            "[2024-03-20 03:06:58,567] [INFO] [checkpointing.py:543:forward] ----Synchronization False\n",
            "[2024-03-20 03:06:58,567] [INFO] [checkpointing.py:544:forward] ----Profiling time in checkpointing False\n",
            "[2024-03-20 03:07:00,916] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\n",
            "[2024-03-20 03:07:01,600] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
            "[2024-03-20 03:07:07,271] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:07,272] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=11.349030187730612, CurrSamplesPerSec=11.873925825898512, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:14,090] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:14,090] [INFO] [timer.py:260:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=11.593294605442116, CurrSamplesPerSec=11.841024453867393, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:20,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:20,890] [INFO] [timer.py:260:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=11.67654268464161, CurrSamplesPerSec=11.834304934870543, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:27,678] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:27,679] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=11.7214958032402, CurrSamplesPerSec=11.89509029857519, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:34,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:34,460] [INFO] [timer.py:260:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=11.750570526689806, CurrSamplesPerSec=11.88056002271702, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:34,460] [INFO] [RANK 0]  iteration       50/     500 | elapsed time per iteration (ms): 757.9 | learning rate 5.000E-06 | total loss 4.529375E+00 | loss 4.529375E+00 | loss scale 32768.0 |speed 633.36 samples/(min*GPU)\n",
            "[2024-03-20 03:07:34,462] [INFO] [RANK 0] after 50 iterations memory (MB) | allocated: 14932.1767578125 | max allocated: 20608.76611328125 | cached: 23502.0 | max cached: 23502.0\n",
            "[2024-03-20 03:07:34,463] [INFO] [RANK 0] time (ms) | forward: 327.75 | backward: 418.85 | allreduce: 0.00 | optimizer: 9.73 | batch generator: 5.40 | data loader: 0.66\n",
            "[2024-03-20 03:07:41,259] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:41,260] [INFO] [timer.py:260:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=11.765688595469284, CurrSamplesPerSec=11.779366329223327, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:48,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:48,053] [INFO] [timer.py:260:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=11.777006103414118, CurrSamplesPerSec=11.766441561647659, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:07:54,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:07:54,863] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=11.781667208608493, CurrSamplesPerSec=11.815132216930275, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:01,657] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:01,657] [INFO] [timer.py:260:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=11.788368761910048, CurrSamplesPerSec=11.799460285554938, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:08,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=2, lr=[5e-06], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:08,449] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=11.793992312870637, CurrSamplesPerSec=11.832823407769771, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:08,450] [INFO] [RANK 0]  iteration      100/     500 | elapsed time per iteration (ms): 679.8 | learning rate 5.000E-06 | total loss 4.520469E+00 | loss 4.520469E+00 | loss scale 32768.0 |speed 706.10 samples/(min*GPU)\n",
            "[2024-03-20 03:08:08,450] [INFO] [RANK 0] time (ms) | forward: 267.34 | backward: 407.01 | allreduce: 0.00 | optimizer: 4.19 | batch generator: 3.19 | data loader: 0.30\n",
            "[2024-03-20 03:08:15,259] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=2, lr=[9.173526628227329e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:15,260] [INFO] [timer.py:260:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=11.795753631928857, CurrSamplesPerSec=11.85364047693738, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:22,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=2, lr=[9.003080357051608e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:22,100] [INFO] [timer.py:260:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=11.792662277836566, CurrSamplesPerSec=11.794333984074305, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:28,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=2, lr=[8.818809028111783e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:28,913] [INFO] [timer.py:260:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=11.793908483087684, CurrSamplesPerSec=11.795171473164697, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:35,768] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=2, lr=[8.621439876157625e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:35,768] [INFO] [timer.py:260:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=11.78958856700025, CurrSamplesPerSec=11.791457576038706, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:42,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=2, lr=[8.411751827062499e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:42,588] [INFO] [timer.py:260:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=11.79010222000827, CurrSamplesPerSec=11.614199226260753, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:42,589] [INFO] [RANK 0]  iteration      150/     500 | elapsed time per iteration (ms): 682.8 | learning rate 8.390E-05 | total loss 4.498984E+00 | loss 4.498984E+00 | loss scale 32768.0 |speed 703.00 samples/(min*GPU)\n",
            "[2024-03-20 03:08:42,590] [INFO] [RANK 0] time (ms) | forward: 268.53 | backward: 408.14 | allreduce: 0.00 | optimizer: 4.88 | batch generator: 3.14 | data loader: 0.29\n",
            "[2024-03-20 03:08:49,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=2, lr=[8.190572423758837e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:49,425] [INFO] [timer.py:260:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=11.788770782777366, CurrSamplesPerSec=11.798900157215842, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:08:56,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=2, lr=[7.958774560304211e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:08:56,263] [INFO] [timer.py:260:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=11.787268088834521, CurrSamplesPerSec=11.819635404484599, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:03,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=2, lr=[7.717273036967313e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:03,076] [INFO] [timer.py:260:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=11.788350642880882, CurrSamplesPerSec=11.838793512845246, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:09,902] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=2, lr=[7.4670209499292e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:09,903] [INFO] [timer.py:260:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=11.788455150241708, CurrSamplesPerSec=11.808820217126897, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:16,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=2, lr=[7.209005929848107e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:16,744] [INFO] [timer.py:260:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=11.787344619556738, CurrSamplesPerSec=11.57222164550776, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:16,745] [INFO] [RANK 0]  iteration      200/     500 | elapsed time per iteration (ms): 683.1 | learning rate 7.183E-05 | total loss 4.331992E+00 | loss 4.331992E+00 | loss scale 32768.0 |speed 702.67 samples/(min*GPU)\n",
            "[2024-03-20 03:09:16,745] [INFO] [RANK 0] time (ms) | forward: 269.11 | backward: 408.51 | allreduce: 0.00 | optimizer: 4.30 | batch generator: 3.27 | data loader: 0.24\n",
            "[2024-03-20 03:09:23,550] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=2, lr=[6.944246244132443e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:23,550] [INFO] [timer.py:260:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=11.788947285995306, CurrSamplesPerSec=11.772431589454277, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:30,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=2, lr=[6.673786778304537e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:30,368] [INFO] [timer.py:260:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=11.789382514145338, CurrSamplesPerSec=11.74165472826996, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:37,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=2, lr=[6.398694912314831e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:37,193] [INFO] [timer.py:260:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=11.789347626470747, CurrSamplesPerSec=11.796382311208985, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:44,054] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=2, lr=[6.120056308080872e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:44,055] [INFO] [timer.py:260:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=11.786969097189115, CurrSamplesPerSec=11.762704496791011, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:50,881] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=2, lr=[5.838970624875698e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:50,882] [INFO] [timer.py:260:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=11.787077574021305, CurrSamplesPerSec=11.702375530024922, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:09:50,883] [INFO] [RANK 0]  iteration      250/     500 | elapsed time per iteration (ms): 682.8 | learning rate 5.811E-05 | total loss 4.129375E+00 | loss 4.129375E+00 | loss scale 32768.0 |speed 703.03 samples/(min*GPU)\n",
            "[2024-03-20 03:09:50,883] [INFO] [RANK 0] time (ms) | forward: 268.71 | backward: 408.65 | allreduce: 0.00 | optimizer: 4.21 | batch generator: 3.32 | data loader: 0.24\n",
            "[2024-03-20 03:09:57,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=2, lr=[5.556547179475088e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:09:57,689] [INFO] [timer.py:260:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=11.788295632003585, CurrSamplesPerSec=11.815951857852626, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:04,507] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=2, lr=[5.273900568191038e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:04,508] [INFO] [timer.py:260:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=11.788657321717162, CurrSamplesPerSec=11.759814643538931, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:11,329] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=2, lr=[4.9921462680693324e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:11,330] [INFO] [timer.py:260:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=11.788729586134806, CurrSamplesPerSec=11.801136839232418, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:18,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=2, lr=[4.712396234611258e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:18,167] [INFO] [timer.py:260:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=11.787914005502834, CurrSamplesPerSec=11.785352969481549, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:25,047] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=2, lr=[4.43575451339324e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:25,048] [INFO] [timer.py:260:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=11.784671136364858, CurrSamplesPerSec=11.719296529939808, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:25,048] [INFO] [RANK 0]  iteration      300/     500 | elapsed time per iteration (ms): 683.3 | learning rate 4.408E-05 | total loss 4.041953E+00 | loss 4.041953E+00 | loss scale 32768.0 |speed 702.45 samples/(min*GPU)\n",
            "[2024-03-20 03:10:25,049] [INFO] [RANK 0] time (ms) | forward: 269.04 | backward: 408.73 | allreduce: 0.00 | optimizer: 4.35 | batch generator: 3.11 | data loader: 0.27\n",
            "[2024-03-20 03:10:31,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=2, lr=[4.163312882903344e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:31,904] [INFO] [timer.py:260:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=11.783049344177163, CurrSamplesPerSec=11.814212856602145, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:38,741] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=2, lr=[3.896146545790372e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:38,742] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=11.782441700070779, CurrSamplesPerSec=11.607943420220545, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:45,564] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=2, lr=[3.6353098855302215e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:45,564] [INFO] [timer.py:260:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=11.782652781646753, CurrSamplesPerSec=11.785733804747249, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:52,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=2, lr=[3.381832305256004e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:52,394] [INFO] [timer.py:260:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=11.782553344126436, CurrSamplesPerSec=11.830658124332079, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:59,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=2, lr=[3.1367141651741694e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:10:59,224] [INFO] [timer.py:260:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=11.782357521693037, CurrSamplesPerSec=11.837310861758823, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:10:59,225] [INFO] [RANK 0]  iteration      350/     500 | elapsed time per iteration (ms): 683.5 | learning rate 3.113E-05 | total loss 3.943164E+00 | loss 3.943164E+00 | loss scale 32768.0 |speed 702.25 samples/(min*GPU)\n",
            "[2024-03-20 03:10:59,225] [INFO] [RANK 0] time (ms) | forward: 269.51 | backward: 408.64 | allreduce: 0.00 | optimizer: 4.20 | batch generator: 3.10 | data loader: 0.25\n",
            "[2024-03-20 03:11:06,030] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=2, lr=[2.900922834599797e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:06,030] [INFO] [timer.py:260:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=11.783395136790405, CurrSamplesPerSec=11.740274353740402, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:12,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=2, lr=[2.6753888741918488e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:12,857] [INFO] [timer.py:260:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=11.783366109642673, CurrSamplesPerSec=11.631583672730814, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:19,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=2, lr=[2.4610023634553902e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:19,685] [INFO] [timer.py:260:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=11.783290670800104, CurrSamplesPerSec=11.762110744837624, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:26,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=2, lr=[2.2586093880044187e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:26,517] [INFO] [timer.py:260:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=11.782971088422329, CurrSamplesPerSec=11.805301234660853, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:33,358] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=2, lr=[2.0690087004484844e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:33,358] [INFO] [timer.py:260:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=11.78231071788292, CurrSamplesPerSec=11.766585977134108, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:33,359] [INFO] [RANK 0]  iteration      400/     500 | elapsed time per iteration (ms): 682.7 | learning rate 2.051E-05 | total loss 3.892344E+00 | loss 3.892344E+00 | loss scale 32768.0 |speed 703.10 samples/(min*GPU)\n",
            "[2024-03-20 03:11:33,359] [INFO] [RANK 0] time (ms) | forward: 268.63 | backward: 408.78 | allreduce: 0.00 | optimizer: 4.10 | batch generator: 3.03 | data loader: 0.26\n",
            "[2024-03-20 03:11:35,405] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\n",
            "[2024-03-20 03:11:36,083] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
            "[2024-03-20 03:11:40,173] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=4, lr=[1.927043206084741e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:40,174] [INFO] [timer.py:260:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=11.782842179182596, CurrSamplesPerSec=11.797742727151265, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:47,033] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=4, lr=[1.7623184536188427e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:47,034] [INFO] [timer.py:260:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=11.781438307812765, CurrSamplesPerSec=11.760577163029488, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:11:53,870] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=4, lr=[1.6123446226322414e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:11:53,871] [INFO] [timer.py:260:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=11.781010484245993, CurrSamplesPerSec=11.533281065197567, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:00,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=4, lr=[1.4777135913193132e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:00,707] [INFO] [timer.py:260:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=11.780803610297333, CurrSamplesPerSec=11.790546039251183, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:07,568] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=4, lr=[1.3589566868535836e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:07,569] [INFO] [timer.py:260:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=11.779483859842241, CurrSamplesPerSec=11.603720446409305, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:07,570] [INFO] [RANK 0]  iteration      450/     500 | elapsed time per iteration (ms): 684.2 | learning rate 1.348E-05 | total loss 3.890195E+00 | loss 3.890195E+00 | loss scale 32768.0 |speed 701.54 samples/(min*GPU)\n",
            "[2024-03-20 03:12:07,570] [INFO] [RANK 0] time (ms) | forward: 270.00 | backward: 408.86 | allreduce: 0.00 | optimizer: 4.17 | batch generator: 3.12 | data loader: 0.25\n",
            "[2024-03-20 03:12:14,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=4, lr=[1.2565425884821098e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:14,399] [INFO] [timer.py:260:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=11.779501951906798, CurrSamplesPerSec=11.806588930576927, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:21,236] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=4, lr=[1.1708754778626134e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:21,236] [INFO] [timer.py:260:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=11.77917858817113, CurrSamplesPerSec=11.667981792702475, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:28,064] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=4, lr=[1.1022934439431295e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:28,065] [INFO] [timer.py:260:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=11.779234878819041, CurrSamplesPerSec=11.77944903331757, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:34,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=4, lr=[1.0510671486793873e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:34,884] [INFO] [timer.py:260:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=11.779592048045552, CurrSamplesPerSec=11.794284235989503, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:41,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=4, lr=[1.0173987588557237e-05], mom=[[0.9, 0.95]]\n",
            "[2024-03-20 03:12:41,714] [INFO] [timer.py:260:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=11.779537227386749, CurrSamplesPerSec=11.758969804991592, MemAllocated=14.62GB, MaxMemAllocated=20.13GB\n",
            "[2024-03-20 03:12:41,715] [INFO] [RANK 0]  iteration      500/     500 | elapsed time per iteration (ms): 682.9 | learning rate 1.015E-05 | total loss 3.843828E+00 | loss 3.843828E+00 | loss scale 32768.0 |speed 702.88 samples/(min*GPU)\n",
            "[2024-03-20 03:12:41,715] [INFO] [RANK 0] time (ms) | forward: 268.62 | backward: 408.82 | allreduce: 0.00 | optimizer: 4.27 | batch generator: 3.12 | data loader: 0.26\n",
            "[2024-03-20 03:12:41,716] [INFO] [RANK 0] Saving Model...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  warnings.warn(\n",
            "[2024-03-20 03:12:41,740] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt\n",
            "[2024-03-20 03:12:41,741] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt...\n",
            "[2024-03-20 03:13:27,957] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt.\n",
            "[2024-03-20 03:13:30,898] [INFO] [RANK 0] Saving Model...\n",
            "[2024-03-20 03:13:30,912] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt\n",
            "[2024-03-20 03:13:30,913] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt...\n",
            "[2024-03-20 03:14:19,529] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ./checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt.\n",
            "[2024-03-20 03:14:24,815] [INFO] [launch.py:348:main] Process 4007 exits successfully.\n"
          ]
        }
      ],
      "source": [
        "!bash finetune_XrayGLM.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def copy_folder(source_folder, destination_folder):\n",
        "    shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "\n",
        "copy_folder('/content/XrayGLM/checkpoints/finetune-XrayGLM-03-20-03-04', '/content/drive/MyDrive/finetune-XrayGLM-03-20-03-04')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0E1sIfnnkxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def copy_file(source_file, destination_file):\n",
        "    shutil.copy(source_file, destination_file)\n",
        "\n",
        "copy_file('/content/XrayGLM/checkpoints/finetune-XrayGLM-03-20-03-04/500/mp_rank_00_model_states.pt', '/content/drive/MyDrive/finetune-XrayGLM-03-20-03-04/500')\n"
      ],
      "metadata": {
        "id": "KIrOMU7H6KMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}